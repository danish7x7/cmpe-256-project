{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f333973-7364-47f5-8b28-838d8cf794c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "import ast\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480b2e77-1d57-4d7a-b758-fd91d587812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_name</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_type</th>\n",
       "      <th>category_type_name</th>\n",
       "      <th>eval_status</th>\n",
       "      <th>positive_attributes</th>\n",
       "      <th>absolute_path</th>\n",
       "      <th>num_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>232</td>\n",
       "      <td>273</td>\n",
       "      <td>160</td>\n",
       "      <td>194</td>\n",
       "      <td>31040</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>upper-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[717, 818]</td>\n",
       "      <td>../data/img/Sheer_Pleated-Front_Blouse/img_000...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>155</td>\n",
       "      <td>161</td>\n",
       "      <td>88</td>\n",
       "      <td>102</td>\n",
       "      <td>8976</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>upper-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[717, 818]</td>\n",
       "      <td>../data/img/Sheer_Pleated-Front_Blouse/img_000...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>156</td>\n",
       "      <td>200</td>\n",
       "      <td>91</td>\n",
       "      <td>135</td>\n",
       "      <td>12285</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>upper-body</td>\n",
       "      <td>val</td>\n",
       "      <td>[141, 717, 837, 956]</td>\n",
       "      <td>../data/img/Sheer_Pleated-Front_Blouse/img_000...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>167</td>\n",
       "      <td>182</td>\n",
       "      <td>116</td>\n",
       "      <td>120</td>\n",
       "      <td>13920</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>upper-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[716]</td>\n",
       "      <td>../data/img/Sheer_Pleated-Front_Blouse/img_000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>46</td>\n",
       "      <td>88</td>\n",
       "      <td>166</td>\n",
       "      <td>262</td>\n",
       "      <td>120</td>\n",
       "      <td>174</td>\n",
       "      <td>20880</td>\n",
       "      <td>3</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>upper-body</td>\n",
       "      <td>test</td>\n",
       "      <td>[349, 405, 717, 810]</td>\n",
       "      <td>../data/img/Sheer_Pleated-Front_Blouse/img_000...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289207</th>\n",
       "      <td>289207</td>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000050.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>89401</td>\n",
       "      <td>41</td>\n",
       "      <td>Dress</td>\n",
       "      <td>3</td>\n",
       "      <td>full-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[30, 681, 682, 730]</td>\n",
       "      <td>../data/img/Paisley_Print_Babydoll_Dress/img_0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289208</th>\n",
       "      <td>289208</td>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000051.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>225</td>\n",
       "      <td>277</td>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>46209</td>\n",
       "      <td>41</td>\n",
       "      <td>Dress</td>\n",
       "      <td>3</td>\n",
       "      <td>full-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[275, 681]</td>\n",
       "      <td>../data/img/Paisley_Print_Babydoll_Dress/img_0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289209</th>\n",
       "      <td>289209</td>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000052.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>149</td>\n",
       "      <td>230</td>\n",
       "      <td>131</td>\n",
       "      <td>189</td>\n",
       "      <td>24759</td>\n",
       "      <td>41</td>\n",
       "      <td>Dress</td>\n",
       "      <td>3</td>\n",
       "      <td>full-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[30, 681]</td>\n",
       "      <td>../data/img/Paisley_Print_Babydoll_Dress/img_0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289210</th>\n",
       "      <td>289210</td>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000053.jpg</td>\n",
       "      <td>75</td>\n",
       "      <td>47</td>\n",
       "      <td>220</td>\n",
       "      <td>300</td>\n",
       "      <td>145</td>\n",
       "      <td>253</td>\n",
       "      <td>36685</td>\n",
       "      <td>41</td>\n",
       "      <td>Dress</td>\n",
       "      <td>3</td>\n",
       "      <td>full-body</td>\n",
       "      <td>train</td>\n",
       "      <td>[30, 681, 682, 730]</td>\n",
       "      <td>../data/img/Paisley_Print_Babydoll_Dress/img_0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289211</th>\n",
       "      <td>289211</td>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000054.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>63</td>\n",
       "      <td>202</td>\n",
       "      <td>296</td>\n",
       "      <td>166</td>\n",
       "      <td>233</td>\n",
       "      <td>38678</td>\n",
       "      <td>41</td>\n",
       "      <td>Dress</td>\n",
       "      <td>3</td>\n",
       "      <td>full-body</td>\n",
       "      <td>val</td>\n",
       "      <td>[30, 681, 760, 880]</td>\n",
       "      <td>../data/img/Paisley_Print_Babydoll_Dress/img_0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289212 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         image_name  x_1  y_1  \\\n",
       "0            0    img/Sheer_Pleated-Front_Blouse/img_00000001.jpg   72   79   \n",
       "1            1    img/Sheer_Pleated-Front_Blouse/img_00000002.jpg   67   59   \n",
       "2            2    img/Sheer_Pleated-Front_Blouse/img_00000003.jpg   65   65   \n",
       "3            3    img/Sheer_Pleated-Front_Blouse/img_00000004.jpg   51   62   \n",
       "4            4    img/Sheer_Pleated-Front_Blouse/img_00000005.jpg   46   88   \n",
       "...        ...                                                ...  ...  ...   \n",
       "289207  289207  img/Paisley_Print_Babydoll_Dress/img_00000050.jpg    1    1   \n",
       "289208  289208  img/Paisley_Print_Babydoll_Dress/img_00000051.jpg   14   58   \n",
       "289209  289209  img/Paisley_Print_Babydoll_Dress/img_00000052.jpg   18   41   \n",
       "289210  289210  img/Paisley_Print_Babydoll_Dress/img_00000053.jpg   75   47   \n",
       "289211  289211  img/Paisley_Print_Babydoll_Dress/img_00000054.jpg   36   63   \n",
       "\n",
       "        x_2  y_2  width  height   area  category_id category_name  \\\n",
       "0       232  273    160     194  31040            3        Blouse   \n",
       "1       155  161     88     102   8976            3        Blouse   \n",
       "2       156  200     91     135  12285            3        Blouse   \n",
       "3       167  182    116     120  13920            3        Blouse   \n",
       "4       166  262    120     174  20880            3        Blouse   \n",
       "...     ...  ...    ...     ...    ...          ...           ...   \n",
       "289207  300  300    299     299  89401           41         Dress   \n",
       "289208  225  277    211     219  46209           41         Dress   \n",
       "289209  149  230    131     189  24759           41         Dress   \n",
       "289210  220  300    145     253  36685           41         Dress   \n",
       "289211  202  296    166     233  38678           41         Dress   \n",
       "\n",
       "        category_type category_type_name eval_status   positive_attributes  \\\n",
       "0                   1         upper-body       train            [717, 818]   \n",
       "1                   1         upper-body       train            [717, 818]   \n",
       "2                   1         upper-body         val  [141, 717, 837, 956]   \n",
       "3                   1         upper-body       train                 [716]   \n",
       "4                   1         upper-body        test  [349, 405, 717, 810]   \n",
       "...               ...                ...         ...                   ...   \n",
       "289207              3          full-body       train   [30, 681, 682, 730]   \n",
       "289208              3          full-body       train            [275, 681]   \n",
       "289209              3          full-body       train             [30, 681]   \n",
       "289210              3          full-body       train   [30, 681, 682, 730]   \n",
       "289211              3          full-body         val   [30, 681, 760, 880]   \n",
       "\n",
       "                                            absolute_path  num_attributes  \n",
       "0       ../data/img/Sheer_Pleated-Front_Blouse/img_000...               2  \n",
       "1       ../data/img/Sheer_Pleated-Front_Blouse/img_000...               2  \n",
       "2       ../data/img/Sheer_Pleated-Front_Blouse/img_000...               4  \n",
       "3       ../data/img/Sheer_Pleated-Front_Blouse/img_000...               1  \n",
       "4       ../data/img/Sheer_Pleated-Front_Blouse/img_000...               4  \n",
       "...                                                   ...             ...  \n",
       "289207  ../data/img/Paisley_Print_Babydoll_Dress/img_0...               4  \n",
       "289208  ../data/img/Paisley_Print_Babydoll_Dress/img_0...               2  \n",
       "289209  ../data/img/Paisley_Print_Babydoll_Dress/img_0...               2  \n",
       "289210  ../data/img/Paisley_Print_Babydoll_Dress/img_0...               4  \n",
       "289211  ../data/img/Paisley_Print_Babydoll_Dress/img_0...               4  \n",
       "\n",
       "[289212 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_df = pd.read_csv(\"../data/cleaned_data/fashion_dataset.csv\")\n",
    "fashion_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225b5007-3afa-48a1-9aef-663f292863ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attributes_cloth(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    num_attributes = int(lines[0].strip())\n",
    "    columns = lines[1].strip().split()\n",
    "    \n",
    "    data = []\n",
    "    for i in range(2, len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        parts = line.split()\n",
    "        \n",
    "        attr_type = int(parts[-1])\n",
    "        attr_name = ' '.join(parts[:-1])\n",
    "        \n",
    "        attr_id = i - 2\n",
    "        \n",
    "        data.append([attr_id, attr_name, attr_type])\n",
    "    \n",
    "    attr_df = pd.DataFrame(data, columns=['attr_id', 'attr_name', 'attr_type'])\n",
    "    attr_df['attr_type_name'] = attr_df['attr_type'].map({\n",
    "        1: 'texture', \n",
    "        2: 'fabric', \n",
    "        3: 'shape', \n",
    "        4: 'part', \n",
    "        5: 'style'\n",
    "    })\n",
    "    \n",
    "    return attr_df\n",
    "attr_df = load_attributes_cloth(\"../data/Anno_coarse/list_attr_cloth.txt\")\n",
    "attr_id_to_name = dict(zip(attr_df['attr_id'].astype(str), attr_df['attr_name']))\n",
    "attr_id_to_type = dict(zip(attr_df['attr_id'].astype(str), attr_df['attr_type_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7e0a3-c26e-4068-b7ee-f945cc16b84c",
   "metadata": {},
   "source": [
    "# 1. CNN Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff06ef8d-fade-4e1e-9bb2-10fbbf2e1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, crop=True):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.crop = crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = row['absolute_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.crop and all(col in row.index for col in ['x_1', 'y_1', 'x_2', 'y_2']):\n",
    "            x1, y1 = max(0, row['x_1']), max(0, row['y_1'])\n",
    "            x2, y2 = min(image.width, row['x_2']), min(image.height, row['y_2'])\n",
    "\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'category_id': row['category_id'] if 'category_id' in row else -1,\n",
    "            'image_path': img_path,\n",
    "            'index': idx\n",
    "        }\n",
    "\n",
    "        return sample\n",
    "\n",
    "def set_transformations(mode='train'):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    if mode == 'train':\n",
    "        # Augment data\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    else:\n",
    "        # validation and testing, no augmentation\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc01a9b-14be-4efc-8d76-6a18f47c40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader):\n",
    "    features = []\n",
    "    image_paths = []\n",
    "    category_ids = []\n",
    "    indices = []\n",
    "    attribute_lists = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            batch_features = output.squeeze().cpu().numpy()\n",
    "\n",
    "            if len(batch_features.shape) == 1:\n",
    "                batch_features = batch_features.reshape(1,-1)\n",
    "\n",
    "            features.append(batch_features)\n",
    "            image_paths.extend(batch['image_path'])\n",
    "            category_ids.extend(batch['category_id'].numpy())\n",
    "            indices.extend(batch['index'].numpy())\n",
    "\n",
    "            for attrs in batch['positive_attributes']:\n",
    "                if isinstance(attrs, str):\n",
    "                    try:\n",
    "                        attrs_list = ast.literal_eval(attrs)\n",
    "                        attribute_lists.append(attrs_list if isinstance(attrs_list, list) else [])\n",
    "                    except:\n",
    "                        all_attributes.append([])\n",
    "                else:\n",
    "                    attribute_lists.append([])\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    return features, image_paths, category_ids, indices, attribute_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527a46b-72e5-4f7d-a677-6835235fa1c4",
   "metadata": {},
   "source": [
    "# 2. Association Rule Mining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb32bcad-e200-4d25-a6cd-cf6fccfb1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_association_rules(fashion_df, attr_df, min_support=0.01, min_confidence=0.5, min_lift=1.0):\n",
    "    all_attributes = []\n",
    "    for attrs in fashion_df['positive_attributes']:\n",
    "        if isinstance(attrs, str):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(attrs)\n",
    "                all_attributes.append(parsed if isinstance(parsed, list) else [])\n",
    "            except:\n",
    "                stripped = attrs.strip('[]')\n",
    "                if stripped:\n",
    "                    items = [item.strip() for item in stripped.split(',')]\n",
    "                    all_attributes.append([int(item) for item in items if item.isdigit()])\n",
    "                else:\n",
    "                    all_attributes.append([])\n",
    "        elif isinstance(attrs, list):\n",
    "            all_attributes.append(attrs)\n",
    "        else:\n",
    "            all_attributes.append([])\n",
    "            \n",
    "    attr_counts = {}\n",
    "    for attr_list in all_attributes:\n",
    "        for attr in attr_list:\n",
    "            attr_id = str(attr)\n",
    "            attr_counts[attr_id] = attr_counts.get(attr_id, 0) + 1\n",
    "\n",
    "    # only use attributes that appear at least 5 times\n",
    "    valid_attrs = {attr_id for attr_id, count in attr_counts.items()\n",
    "                  if count >= 5 and attr_id in attr_df['attr_id'].astype(str).values}\n",
    "\n",
    "    attribute_matrix = []\n",
    "    for attr_list in all_attributes:\n",
    "        item_attrs = {attr_id: 0 for attr_id in valid_attrs}\n",
    "    \n",
    "        for attr in attr_list:\n",
    "            attr_id = str(attr)\n",
    "            if attr_id in valid_attrs:\n",
    "                item_attrs[attr_id] = 1\n",
    "        attribute_matrix.append(item_attrs)\n",
    "    attribute_matrix = pd.DataFrame(attribute_matrix)\n",
    "\n",
    "    attr_mapping = {}\n",
    "    for attr_id in valid_attrs:\n",
    "        attr_name = attr_id_to_name.get(attr_id, \"Unknown\")\n",
    "        attr_type = attr_id_to_type.get(attr_id, \"Unknown\")\n",
    "        attr_mapping[attr_id] = f\"{attr_name} ({attr_type})\"\n",
    "\n",
    "    frequent_itemsets = apriori(attribute_matrix, min_support=0.01, use_colnames=True, max_len=3)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "    rules = rules[rules['lift'] >= 1.0]\n",
    "    rules = rules.sort_values(['confidence', 'lift'], ascending=False)\n",
    "\n",
    "    return rules, attr_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8fee738-db77-495b-87cd-c836608ccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_from_rules(query_attrs, rules, top_n=5):\n",
    "    compl_attributes = []\n",
    "    query_attr_set = set(query_attrs)\n",
    "\n",
    "    # rules where antecedent is a subset of query attrs\n",
    "    for _, rules in rules.iterrows():\n",
    "        antecedent = set(rule['antecedents'])\n",
    "\n",
    "        if antecedent.issubset(query_attr_set):\n",
    "            # add consequents as complementary attrs\n",
    "            for item in rule['consequents']:\n",
    "                if item not in query_attr_set and item not in compl_attributes:\n",
    "                    compl_attributes.append(item)\n",
    "\n",
    "                    if len(compl_attributes) >= top_n:\n",
    "                        return compl_attributes\n",
    "    return compl_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc5048c-1372-46d6-941b-e03b9541cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_similarity(item_attrs, query_attrs, compl_attrs, rule_weight=0.7):\n",
    "    item_attrs_set = set(item_attrs)\n",
    "    query_attrs_set = set(query_attrs)\n",
    "    compl_attrs_set = set(compl_attrs)\n",
    "\n",
    "    # Jaccard similarity\n",
    "    matching_attrs = item_attrs_set.intersection(query_attrs_set)\n",
    "    query_sim = len(matching_attrs) / max(1, len(query_attrs_set.union(item_attrs_set)))\n",
    "\n",
    "    # if complementary, give it more weight\n",
    "    matching_compl = item_attrs_set.intersection(compl_attrs_set)\n",
    "    compl = len(matching_compl) / max(1, len(compl_attrs_set)) if compl_attrs_set else 0\n",
    "\n",
    "    # combine score\n",
    "    score = (rule_weight * query_sim) + ((1 - rule_weight) * compl)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1aefcc-9f98-4e28-953a-e8863398161d",
   "metadata": {},
   "source": [
    "# 3. Hybrid Recommendation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1bd8e-5e8a-47b3-aff3-b6abc710e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations(query_idx, fashion_df, features, indices, attribute_lists, rules, \n",
    "                           k=5, visual_weight=0.6, attr_weight=0.4):\n",
    "    # extract features and attributes from query item\n",
    "    query_feature = features[query_idx].reshape(1,-1)\n",
    "    query_attrs = attribute_lists[query_idx]\n",
    "\n",
    "    # get complementary attributes from generated association rules\n",
    "    compl_attrs = attributes_from_rules(query_attrs, rules)\n",
    "\n",
    "    # visual similar items\n",
    "    knn = NearestNeighbors(metric='cosine')\n",
    "    knn.fit(features)\n",
    "\n",
    "    distances, neighbor_indices = knn.kneighbors(query_feature, n_neighbors=min(k*3, len(features)))\n",
    "\n",
    "    distances = distances.flatten.tolist()\n",
    "    neighbor_indices = neighbor_indices.flatten().tolist()\n",
    "\n",
    "    # if query is in neighbors, remove (don't want to recommend query)\n",
    "    if query_idx in neighbor_indices:\n",
    "        idx = neighbor_indices.index(query_idx)\n",
    "        neighbhor_indices.pop(idx)\n",
    "        distances.pop(idx)\n",
    "\n",
    "    attr_scores = []\n",
    "    for idx in neighbor_indices:\n",
    "        neighbor_attrs = attribute_lists[idx]\n",
    "        attr_score = attribute_similarity(neighbor_attrs, query_attrs, compl_attrs)\n",
    "        attr_scores.append(attr_score)\n",
    "\n",
    "    # normalize scores\n",
    "    max_distance = max(distances) if distances else 1\n",
    "    norm_distances = [1 - (d / max_distance) for d in distances]\n",
    "\n",
    "    max_attr_score = max(attr_scores) if attr_scores and max(attr_scores) > 0 else 1\n",
    "    norm_attr_scores = [s / max_attr_score for s in attr_scores]\n",
    "\n",
    "    combined_scores = [(visual_weight * dist + attr_weight * attr_score) for dist, attr_score \n",
    "                      in zip(norm_distances, norm_attr_scores)]\n",
    "\n",
    "    # Sort scores and get the top k\n",
    "    recommendations = sorted(zip(neighbor_indices, combined_scores), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    recommendation_indices = [idx for idx, _ in recommendations]\n",
    "    recommendation_scores = [score for _, score in recommendations]\n",
    "\n",
    "    original_indices = [indices[idx] for idx in recommendation_indices]\n",
    "\n",
    "    return original_indices, recommendation_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e69b1-6a62-4fea-98ca-46021e245058",
   "metadata": {},
   "source": [
    "# 4. Run Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e68b9c90-ab3a-4657-8be3-3725c091b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up datasets\n",
    "transform = set_transformations(mode='val')\n",
    "dataset = FashionDataset(fashion_df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1c4158-5a92-4886-bee7-90569996b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove classification layer\n",
    "model = models.resnet50(pretrained=True)\n",
    "feature_model = nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ded5d-40ce-4485-821a-63117cc68507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'FashionDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "features, image_paths, category_ids, indices, attribute_lists = extract_features(feature_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c162375-6465-4e7c-b7c6-aacbbfb746d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create association rules and get mapping for attributes\n",
    "rules, attr_mapping = create_association_rules(fashion_df, attr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485bb7d-4c9b-488c-a2da-4a3d5c1ca62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_items = random.sample(range(len(indices)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b08b0-eca3-4168-a8ad-048629e65739",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx in sample_items:\n",
    "    query_idx = idx\n",
    "    query_original_idx = indices[query_idx]\n",
    "\n",
    "    print(f\"Item {query_idx}, Original Index: {query_original_idx}\")\n",
    "    print(f\"Category: {fashion_df.iloc[query_original_idx]['category_name']}\")\n",
    "\n",
    "    # only get valid attributes\n",
    "    query_attrs_list = fashion_df.iloc[query_original_idx]['positive_attributes']\n",
    "    if isinstance(query_attrs_list, str):\n",
    "        try:\n",
    "            query_attrs = ast.literal_eval(query_attrs_list)\n",
    "        except:\n",
    "            query_attrs = []\n",
    "    else:\n",
    "        query_attrs = query_attrs_list if isinstance(query_attrs_list, list) else []\n",
    "\n",
    "    rec_indices, rec_scores = hybrid_recommendations(query_idx, fashion_df, features, indices, \n",
    "                                                     attribute_lists, rules, k=5)\n",
    "    print(f\"Top 5 Recommendations for {query_idx}\")\n",
    "    for i, (rec_idx, score) in enumerate(zip(rec_indices, rec_scores)):\n",
    "        rec_item = fashion_df.iloc[rec_idx]\n",
    "        print(f\"{i+1}. {rec_item['category_name']} - Score: {score:.4f})\")\n",
    "\n",
    "    results.append({\n",
    "        'query_index': query_original_idx,\n",
    "        'recommendations' : rec_indices,\n",
    "        'scores': rec_scores\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1a71d-86fc-4f79-8ba2-318bff06cbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
